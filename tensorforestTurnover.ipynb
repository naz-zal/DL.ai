{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#dependencies\nimport math\nimport pandas as pd \n\n#loading the data\ndf = pd.read_csv(\"../input/HR_comma_sep.csv\")\n\n#checking for NULL values\nprint(\"\\033[1m\" + \"\\033[94m\" + \"Data types:\\n\" + 11 * \"-\")\nprint(\"\\033[30m\" + \"{}\\n\".format(df.dtypes))\nprint(\"\\033[1m\" + \"\\033[94m\" + \"Sum of null values in each column:\\n\" + 35 * \"-\")\nprint(\"\\033[30m\" + \"{}\".format(df.isnull().sum()))\ndf.head()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Map salary into integers\nsalary_map = {\"low\": 0, \"medium\": 1, \"high\": 2}\ndf[\"salary\"] = df[\"salary\"].map(salary_map)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1645b180-062a-4537-84b6-1c420c2f847b",
        "_uuid": "8e885b5f143e0f9dfa7c0ffeb91448238a0ff2cd",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df = df.drop('Work_accident', axis = 1)\ndf = df.drop('Department', axis = 1)\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5846bfe8-111d-4fcc-94cc-aebd9f1e18c2",
        "_uuid": "10d31c73965451f2a91e0600385bca60700f9405",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function\n\nimport tensorflow as tf\nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.python.ops import resources",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f7a2979e-8521-4416-8427-3909f5b1f661",
        "_uuid": "3eef297a14422fc5e94541fba13b8e121a9c0b15",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Parameters\nnum_steps = 500 # Total steps to train\nbatch_size = 1024 # The number of samples per batch\nnum_classes = 2 # The 10 digits\nnum_features = 7 # Each image is 28x28 pixels\nnum_trees = 10\nmax_nodes = 1000",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "aee55f88-3bcd-4f52-b81b-31cc0313d3a6",
        "_uuid": "49a3ff9385c5f699cd4d354fcece84fe7dee6f5a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "272e4645-915c-41ed-af35-c8b2282ff500",
        "_uuid": "3bd2a5795721385501e08d3e39f25c743d4dc60e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "x = df.loc[:, df.columns != \"left\"].values\ny = df.loc[:, df.columns == \"left\"].values.flatten()\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 1)\n\n#upsampling minority classes \nx_train_u, y_train_u = resample(x_train[y_train == 1], y_train[y_train == 1], replace=True, n_samples = x_train[y_train == 0].shape[0],\n                                random_state=1)\n\nx_train_u = np.concatenate((x_train[y_train == 0], x_train_u))\ny_train_u = np.concatenate((y_train[y_train == 0], y_train_u))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "65019315-2f33-407d-bb91-b8864b28e1af",
        "_uuid": "6e772a7ffe434f4455e4849c5a24b7e06f6d41bd",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Input and Target data\nX = tf.placeholder(tf.float32, shape=[None, num_features])\n# For random forest, labels must be integers (the class id)\nY = tf.placeholder(tf.int32, shape=[None])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fabeee00-9375-434f-b4de-30b3a455d6e1",
        "_uuid": "8250cc4b773ac9c0aaaa7e41ecdf81c1dd641c8d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Random Forest Parameters\nhparams = tensor_forest.ForestHParams(num_classes=num_classes,\n                                      num_features=num_features,\n                                      num_trees=num_trees,\n                                      max_nodes=max_nodes).fill()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "201f31f4-3697-4da2-b352-55e45d118119",
        "_uuid": "26d4602beb83ee289e8e94a3b506dc2d999098ce",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    mini_batch_size - size of the mini-batches, integer\n    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = X[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :]\n        mini_batch_Y = Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = X[num_complete_minibatches * mini_batch_size : m, :]\n        mini_batch_Y = Y[num_complete_minibatches * mini_batch_size : m]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3ade465a-4dc8-4f83-bcc1-76af8cf60e6d",
        "_uuid": "7ebe75cfbc1907ff2b995a9d58b4100a927076c4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Build the Random Forest\nforest_graph = tensor_forest.RandomForestGraphs(hparams)\n# Get training graph and loss\ntrain_op = forest_graph.training_graph(X, Y)\nloss_op = forest_graph.training_loss(X, Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "383799c1-00bd-45cd-adf8-b453fd4183a1",
        "_uuid": "6b844dbad6571caef8a8256776937e0cfa6376d3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Measure the accuracy\ninfer_op, _, _ = forest_graph.inference_graph(X)\ncorrect_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\naccuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Initialize the variables (i.e. assign their default value) and forest resources\ninit_vars = tf.group(tf.global_variables_initializer(),\n    resources.initialize_resources(resources.shared_resources()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6b83fb01-e7c6-4a5a-af4e-1ae08da5f009",
        "_uuid": "bfdb0cf6cbe2d5985d93cd11323c60ba30266814",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Start TensorFlow session\nsess = tf.Session()\n\n# Run the initializer\nsess.run(init_vars)\n\n# Training\nfor i in range(1, num_steps + 1):\n    # Prepare Data\n    # Get the next batch of MNIST data (only images are needed, not labels)\n    minibatches = random_mini_batches(x_train_u, y_train_u, batch_size)\n    for minibatch in minibatches:\n        (batch_x, batch_y) = minibatch\n        _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n    if i % 50 == 0 or i == 1:\n        acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n        print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a67e817b-5da5-414a-8e11-149ffa374fc4",
        "_uuid": "0ec29c5f5786cdfa608f9e4efb9f5484560e8aba",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Test Model\nprint(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: x_test, Y: y_test}))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0c24c96d-83a8-4095-a9b2-a7e160899e64",
        "_uuid": "dcbd081d117bd35b0d06d7b73d2ec92836652de2",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1cf9cb63-435c-4071-8898-a503c269fbdd",
        "_uuid": "b12b9ad85db23326255e69fbc946244dfe740979",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e99f768e-dc2c-4eb7-96ad-5dbc40e2b253",
        "_uuid": "fd49d7b663ab3b7d0554cdb6b1859dc0fcfe2023",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e0f44cdb-47ad-4871-b4b4-6edbd65a08af",
        "_uuid": "6946defa078d73b97487acd7546dcea3f10e50ac",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "55c67cb7-515e-4773-81c8-b72ccde50b61",
        "_uuid": "964f48b63a054823731e957806140347ec4794c4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "030d33de-6098-4468-9fa6-10752f7ddb5f",
        "_uuid": "e8be48b010223776f3bb81a3f9fbf4e7f66e723a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "version": "3.6.4",
      "file_extension": ".py",
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}