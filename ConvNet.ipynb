{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_anaconda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing modules\n",
    "\n",
    "from __future__ import print_function\n",
    "import random \n",
    "from os import listdir\n",
    "import glob \n",
    "\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting dimensions for images from MNIST dataset\n",
    "\n",
    "mnist_image_height = 28\n",
    "mnist_image_width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing dataset from keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset: (60000, 28, 28)\n",
      "Shape of test dataset: (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef3aefcb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of x_train[0] = 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training dataset: {}\".format(np.shape(x_train)))\n",
    "print(\"Shape of test dataset: {}\".format(np.shape(x_test)))\n",
    "\n",
    "#showing x_train[0]\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0], cmap = \"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label of x_train[0] = {}\".format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creating a sequence of these digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synth_data(data, labels, dataset_size):\n",
    "    \n",
    "    synth_img_height = 64\n",
    "    synth_img_width = 64\n",
    "    \n",
    "    synth_data = np.ndarray(shape = (dataset_size, synth_img_height, synth_img_width), dtype = np.float32)\n",
    "    \n",
    "    synth_labels = []\n",
    "    \n",
    "    #looping over the no. of images we want \n",
    "    for i in range(dataset_size):\n",
    "        \n",
    "        #since we're not just doing 5-digit numbers, we'll be declaring number_of_digits\n",
    "        num_digits = random.randint(1,5)\n",
    "        \n",
    "        #a list. picking random indices from dataset. \n",
    "        indices = [random.randint(0, len(data) - 1) for j in range(num_digits)]\n",
    "        \n",
    "        #stacking the images \n",
    "        new_image = np.hstack([x_train[index] for index in indices])\n",
    "        \n",
    "        #and now labels\n",
    "        new_labels = [y_train[index] for index in indices]\n",
    "        \n",
    "        #to stack with blanks\n",
    "        for blank in range(5 - num_digits):\n",
    "            \n",
    "            new_image = np.hstack([new_image, np.zeros(shape = (28, 28))]) #could use mnist_image_height/width over here \n",
    "            \n",
    "            \n",
    "        new_image = misc.imresize(new_image, (64,64))\n",
    "        \n",
    "        synth_data[i, :, :] = new_image\n",
    "        \n",
    "        synth_labels.append(tuple(new_labels))\n",
    "        \n",
    "    return synth_data, synth_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "x_train_synth, y_train_synth = synth_data(x_train, y_train, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "x_test_synth, y_test_synth = synth_data(x_test, y_test, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDZ+QCKHhExIhNHxCIuT/AWfN7xMnV1WLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef797ca630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9, 9, 7, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_train_synth[224], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "y_train_synth[224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Processing Labels\n",
    "    \n",
    "   This will be done using \"One Hot\" arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#number of classes 0-9 = 10\n",
    "classes = 10 \n",
    "\n",
    "def convert_labels(labels):\n",
    "    \n",
    "    #tp_categorical is in keras\n",
    "    #Each digit array will be of shape (60000,10)\n",
    "    \n",
    "    #declaring arrays where we will (in the next \"for\" loop fill up with Hot Ones)\n",
    "    digOneArr = np.ndarray(shape = (len(labels), classes))\n",
    "    digTwoArr = np.ndarray(shape = (len(labels), classes))\n",
    "    digThrArr = np.ndarray(shape = (len(labels), classes))\n",
    "    digFouArr = np.ndarray(shape = (len(labels), classes))\n",
    "    digFivArr = np.ndarray(shape = (len(labels), classes))\n",
    "    \n",
    "    #looping over individual labels to assign their digit values to the arrays\n",
    "    for index, label in enumerate(labels):\n",
    "        \n",
    "        digOneArr[index, :] = np_utils.to_categorical(label[0], classes)\n",
    "        digTwoArr[index, :] = np_utils.to_categorical(label[0], classes)\n",
    "        digThrArr[index, :] = np_utils.to_categorical(label[0], classes)\n",
    "        digFouArr[index, :] = np_utils.to_categorical(label[0], classes)\n",
    "        digFivArr[index, :] = np_utils.to_categorical(label[0], classes)\n",
    "    \n",
    "    return [digOneArr, digTwoArr, digThrArr, digFouArr, digFivArr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = convert_labels(y_train_synth)\n",
    "test_labels = convert_labels(y_test_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_utils.to_categorical(y_train_synth[224][0],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data_keras(img_data):\n",
    "    \n",
    "    #Reshaping data for keras, with tensorflow as backend\n",
    "    img_data = img_data.reshape(len(img_data),64,64,1)\n",
    "    \n",
    "    #Converting everything to floats\n",
    "    img_data = img_data.astype('float32')\n",
    "    \n",
    "    #Normalizing values between 0 and 1\n",
    "    img_data /= 255\n",
    "    \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = prep_data_keras(x_train_synth)\n",
    "test_images = prep_data_keras(x_test_synth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 64, 64, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 64, 64, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The actual CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required dependencies \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D -> ReLu -> 2DMaxPooling -> dropout -> flattening layer -> softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Feel free to use the suggested outline in the text above to get started, and run through the whole\n",
    "    # exercise (including the later portions of this notebook) once. The come back also try out other\n",
    "    # network architectures as well. \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (3 , 3), strides = (1,1), border_mode = \"same\")(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(32, (3 , 3), strides = (1,1))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    #5 digits\n",
    "    d1 = Dense(10, activation='softmax')(X)\n",
    "    d2 = Dense(10, activation='softmax')(X)\n",
    "    d3 = Dense(10, activation='softmax')(X)\n",
    "    d4 = Dense(10, activation='softmax')(X)\n",
    "    d5 = Dense(10, activation='softmax')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = [d1, d2, d3, d4, d5])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "DigitModel = digitModel((64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DigitModel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DigitModel.fit(x = train_images, y = train_labels, epochs = 12, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_acc(predictions,real_labels):\n",
    "    \n",
    "    individual_counter = 0\n",
    "    global_sequence_counter = 0\n",
    "    for i in range(0,len(predictions[0])):\n",
    "        #Reset sequence counter at the start of each image\n",
    "        sequence_counter = 0 \n",
    "        \n",
    "        for j in range(0,5):\n",
    "            if np.argmax(predictions[j][i]) == np.argmax(real_labels[j][i]):\n",
    "                individual_counter += 1\n",
    "                sequence_counter +=1\n",
    "        \n",
    "        if sequence_counter == 5:\n",
    "            global_sequence_counter += 1\n",
    "         \n",
    "    ind_accuracy = individual_counter/50000.0\n",
    "    global_accuracy = global_sequence_counter/10000.0\n",
    "    \n",
    "    return ind_accuracy,global_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = DigitModel.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_acc(predictions,real_labels):\n",
    "    \n",
    "    individual_counter = 0\n",
    "    global_sequence_counter = 0\n",
    "    for i in range(0,len(predictions[0])):\n",
    "        #Reset sequence counter at the start of each image\n",
    "        sequence_counter = 0 \n",
    "        \n",
    "        for j in range(0,5):\n",
    "            if np.argmax(predictions[j][i]) == np.argmax(real_labels[j][i]):\n",
    "                individual_counter += 1\n",
    "                sequence_counter +=1\n",
    "        \n",
    "        if sequence_counter == 5:\n",
    "            global_sequence_counter += 1\n",
    "         \n",
    "    ind_accuracy = individual_counter/50000.0\n",
    "    global_accuracy = global_sequence_counter/10000.0\n",
    "    \n",
    "    return ind_accuracy,global_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "individual_acc, number_acc = calculate_acc(predictions,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The individual accuracy is {} %\".format(individual_acc*100))\n",
    "print(\"The sequence prediction accuracy is {} %\".format(number_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
